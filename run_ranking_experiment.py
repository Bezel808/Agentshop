#!/usr/bin/env python3
"""
VLM å•†å“æ’åå®éªŒ

è®© VLM å¯¹æœç´¢ç»“æœä¸­çš„æ‰€æœ‰å•†å“è¿›è¡Œæ’åï¼ˆè€Œéåªé€‰ä¸€ä¸ªï¼‰ï¼Œ
å¤šæ¬¡è¿è¡ŒåŒä¸€ query å¹¶ç»Ÿè®¡å¹³å‡æ’åï¼Œè¯„ä¼° VLM å¯¹è´­ç‰©éœ€æ±‚çš„ç†è§£èƒ½åŠ›ã€‚
"""

import sys
import time
import json
import re
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional
from collections import defaultdict

sys.path.insert(0, str(Path(__file__).parent))

from aces.llm_backends import QwenBackend, OpenAIBackend
from aces.core.protocols import Message


@dataclass
class RankingResult:
    """å•æ¬¡æ’åç»“æœ"""
    run_id: int
    query_id: str
    timestamp: str
    extracted_keywords: str
    rankings: Dict[str, int]  # product_name -> rank (1-8)
    reasoning: str


@dataclass
class ExperimentSession:
    """å®Œæ•´å®éªŒä¼šè¯"""
    experiment_id: str
    start_time: str
    end_time: Optional[str] = None
    queries: Dict[str, str] = field(default_factory=dict)  # query_id -> query_text
    results: List[RankingResult] = field(default_factory=list)
    
    def to_dict(self):
        return {
            "experiment_id": self.experiment_id,
            "start_time": self.start_time,
            "end_time": self.end_time,
            "queries": self.queries,
            "results": [asdict(r) for r in self.results]
        }


class VLMRankingExperiment:
    """
    VLM æ’åå®éªŒ
    """
    
    def __init__(
        self,
        llm_api_key: str,
        llm_backend: str = "qwen",
        data_path: str = "datasets_unified/ski_jacket.json",
        log_dir: str = "experiment_logs/ranking_experiment",
    ):
        self.data_path = Path(data_path)
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»º LLM
        if llm_backend == "qwen":
            self.llm = QwenBackend(model="qwen-vl-plus", api_key=llm_api_key)
        else:
            self.llm = OpenAIBackend(model="gpt-4o", api_key=llm_api_key)
        
        # å®éªŒä¼šè¯
        self.session: Optional[ExperimentSession] = None
    
    def _timestamp(self) -> str:
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def log(self, message: str, level: str = "info"):
        """ç®€å•æ—¥å¿—"""
        icons = {"info": "â„¹ï¸", "action": "ğŸ”§", "result": "âœ…", "error": "âŒ", "thinking": "ğŸ¤”"}
        print(f"[{self._timestamp()}] {icons.get(level, 'â€¢')} {message}")

    def load_products(self) -> List[Dict]:
        """ä»æœ¬åœ° JSON åŠ è½½å•†å“åˆ—è¡¨ï¼ˆçº¯æ–‡æœ¬ï¼‰"""
        if not self.data_path.exists():
            raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {self.data_path}")
        with open(self.data_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if not isinstance(data, list):
            raise ValueError("æ•°æ®é›†æ ¼å¼é”™è¯¯ï¼šéœ€è¦ JSON æ•°ç»„")
        return data
    
    def call_llm(self, messages: List[Message]) -> str:
        """è°ƒç”¨ LLM"""
        response = self.llm.generate(messages=messages, tools=None)
        return response.content if isinstance(response.content, str) else str(response.content)
    
    def extract_keywords(self, user_query: str) -> str:
        """æå–æœç´¢å…³é”®è¯"""
        prompt = f"""ç”¨æˆ·æƒ³è´­ä¹°å•†å“ï¼Œéœ€æ±‚å¦‚ä¸‹ï¼š
---
{user_query}
---

è¯·æå–ä¸€ä¸ªç®€çŸ­çš„è‹±æ–‡æœç´¢å…³é”®è¯ï¼ˆ1-2ä¸ªè¯ï¼Œç”¨äºç”µå•†æœç´¢ï¼‰ã€‚

è¦æ±‚ï¼š
1. å¿…é¡»éå¸¸ç®€çŸ­ï¼Œæœ€å¤š2ä¸ªè¯
2. åªåŒ…å«å•†å“ç±»åˆ«åç§°
3. ä¸è¦åŒ…å«ä»»ä½•æŠ€æœ¯è§„æ ¼ã€å“ç‰Œåã€å½¢å®¹è¯

ç¤ºä¾‹ï¼š
- ç”¨æˆ·æƒ³è¦é«˜æ€§èƒ½æ»‘é›ªæœ â†’ ski jacket
- ç”¨æˆ·æƒ³è¦ä¾¿å®œçš„é¼ æ ‡å« â†’ mousepad  
- ç”¨æˆ·æƒ³è¦ä¿æš–ç¾½ç»’æœ â†’ down jacket

åªè¾“å‡ºå…³é”®è¯ï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼š"""

        messages = [
            Message(role="system", content="ä½ åªè¾“å‡º1-2ä¸ªç®€çŸ­çš„è‹±æ–‡æœç´¢å…³é”®è¯ï¼Œä¸è¦å…¶ä»–ä»»ä½•å†…å®¹ã€‚"),
            Message(role="user", content=prompt)
        ]
        
        keywords = self.call_llm(messages).strip().lower()
        # æ¸…ç†ï¼šåªä¿ç•™å­—æ¯å’Œç©ºæ ¼ï¼Œå–å‰ä¸¤ä¸ªè¯
        keywords = re.sub(r'[^a-z\s]', '', keywords)
        words = keywords.split()[:2]
        keywords = ' '.join(words) if words else "ski jacket"
        return keywords
    
    def rank_products(self, user_query: str, products: List[Dict]) -> Dict:
        """è®© LLM å¯¹æ‰€æœ‰å•†å“è¿›è¡Œæ’åï¼ˆçº¯æ–‡æœ¬ï¼Œä¸ä½¿ç”¨å›¾ç‰‡ï¼‰"""
        products_json = json.dumps(products, ensure_ascii=False, indent=2)
        ranking_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è´­ç‰©é¡¾é—®ã€‚ç”¨æˆ·çš„è´­ç‰©éœ€æ±‚æ˜¯ï¼š

---
{user_query}
---

è¯·æ ¹æ®ä¸‹é¢æä¾›çš„å•†å“ JSON æ•°æ®ï¼Œ**å¯¹æ‰€æœ‰å•†å“è¿›è¡Œæ’å**ï¼ˆä»æœ€ç¬¦åˆéœ€æ±‚åˆ°æœ€ä¸ç¬¦åˆï¼‰ã€‚

å•†å“æ•°æ®ï¼š
{products_json}

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

è¯·æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºæ’åç»“æœï¼š

```json
{{
  "rankings": [
    {{"rank": 1, "product": "å•†å“åç§°", "reason": "ç®€çŸ­ç†ç”±"}},
    {{"rank": 2, "product": "å•†å“åç§°", "reason": "ç®€çŸ­ç†ç”±"}},
    {{"rank": 3, "product": "å•†å“åç§°", "reason": "ç®€çŸ­ç†ç”±"}},
    {{"rank": 4, "product": "å•†å“åç§°", "reason": "ç®€çŸ­ç†ç”±"}},
    {{"rank": 5, "product": "å•†å“åç§°", "reason": "ç®€çŸ­ç†ç”±"}},
    {{"rank": 6, "product": "å•†å“åç§°", "reason": "ç®€çŸ­ç†ç”±"}},
    {{"rank": 7, "product": "å•†å“åç§°", "reason": "ç®€çŸ­ç†ç”±"}},
    {{"rank": 8, "product": "å•†å“åç§°", "reason": "ç®€çŸ­ç†ç”±"}}
  ],
  "overall_reasoning": "æ•´ä½“æ’åä¾æ®çš„ç®€è¦è¯´æ˜"
}}
```

æ³¨æ„ï¼š
1. å¿…é¡»å¯¹æ‰€æœ‰ 8 ä¸ªå•†å“è¿›è¡Œæ’å
2. æ’åä» 1ï¼ˆæœ€å¥½ï¼‰åˆ° 8ï¼ˆæœ€å·®ï¼‰
3. å•†å“åç§°è¦ä¸ JSON ä¸­çš„ title å®Œå…¨ä¸€è‡´
4. åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹"""

        messages = [
            Message(role="system", content="ä½ æ˜¯ä¸“ä¸šè´­ç‰©é¡¾é—®ï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·éœ€æ±‚å¯¹å•†å“è¿›è¡Œæ’åã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºã€‚"),
            Message(role="user", content=ranking_prompt)
        ]
        
        response = self.call_llm(messages)
        
        # è§£æ JSON
        try:
            # å°è¯•æå– JSON éƒ¨åˆ†
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                result = json.loads(json_match.group())
                return result
        except json.JSONDecodeError:
            pass
        
        # è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å“åº”
        return {"raw_response": response, "parse_error": True}
    
    def run_single_query(self, query_id: str, user_query: str, run_id: int) -> RankingResult:
        """è¿è¡Œå•æ¬¡æŸ¥è¯¢"""
        self.log(f"[{query_id}] Run {run_id}: å¼€å§‹", "action")
        
        # 1. æå–å…³é”®è¯
        keywords = self.extract_keywords(user_query)
        self.log(f"[{query_id}] Run {run_id}: å…³é”®è¯ = {keywords}", "info")
        
        # 2. åŠ è½½å•†å“æ•°æ®
        products = self.load_products()

        # 3. LLM æ’å
        self.log(f"[{query_id}] Run {run_id}: VLM æ’åä¸­...", "thinking")
        ranking_result = self.rank_products(user_query, products)
        
        # 4. è§£ææ’å
        rankings = {}
        reasoning = ""
        
        if "rankings" in ranking_result:
            for item in ranking_result["rankings"]:
                product_name = item.get("product", "").strip()
                rank = item.get("rank", 0)
                if product_name and rank:
                    rankings[product_name] = rank
            reasoning = ranking_result.get("overall_reasoning", "")
            self.log(f"[{query_id}] Run {run_id}: æ’åå®Œæˆï¼ŒTop-1 = {ranking_result['rankings'][0]['product'][:40]}...", "result")
        else:
            self.log(f"[{query_id}] Run {run_id}: è§£æå¤±è´¥", "error")
            reasoning = ranking_result.get("raw_response", "")[:200]
        
        return RankingResult(
            run_id=run_id,
            query_id=query_id,
            timestamp=self._timestamp(),
            extracted_keywords=keywords,
            rankings=rankings,
            reasoning=reasoning
        )
    
    def run_experiment(self, queries: Dict[str, str], runs_per_query: int = 5):
        """
        è¿è¡Œå®Œæ•´å®éªŒ
        
        Args:
            queries: {query_id: query_text}
            runs_per_query: æ¯ä¸ª query è¿è¡Œæ¬¡æ•°
        """
        experiment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session = ExperimentSession(
            experiment_id=experiment_id,
            start_time=self._timestamp(),
            queries=queries
        )
        
        print("\n" + "="*80)
        print("ğŸ§ª VLM å•†å“æ’åå®éªŒ")
        print("="*80)
        print(f"å®éªŒ ID: {experiment_id}")
        print(f"Query æ•°é‡: {len(queries)}")
        print(f"æ¯ä¸ª Query è¿è¡Œæ¬¡æ•°: {runs_per_query}")
        print(f"æ€»è¿è¡Œæ¬¡æ•°: {len(queries) * runs_per_query}")
        print("="*80 + "\n")
        
        try:
            for query_id, query_text in queries.items():
                print(f"\n{'='*60}")
                print(f"ğŸ“‹ Query: {query_id}")
                print(f"   {query_text[:80]}...")
                print(f"{'='*60}")
                
                for run_id in range(1, runs_per_query + 1):
                    result = self.run_single_query(query_id, query_text, run_id)
                    self.session.results.append(result)
                    time.sleep(1)  # é¿å… API é™æµ
            
            self.session.end_time = self._timestamp()
            
        finally:
            self.save_results()
            self.print_summary()
    
    def save_results(self):
        """ä¿å­˜ç»“æœ"""
        if not self.session:
            return
        
        # ä¿å­˜å®Œæ•´ JSON
        result_file = self.log_dir / f"experiment_{self.session.experiment_id}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(self.session.to_dict(), f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {result_file}")
    
    def print_summary(self):
        """æ‰“å°æ±‡æ€»ç»Ÿè®¡"""
        if not self.session:
            return
        
        print("\n" + "="*80)
        print("ğŸ“Š å®éªŒç»“æœæ±‡æ€»")
        print("="*80)
        
        # æŒ‰ query ç»Ÿè®¡æ¯ä¸ªå•†å“çš„å¹³å‡æ’å
        for query_id in self.session.queries.keys():
            print(f"\n### {query_id}")
            print(f"Query: {self.session.queries[query_id][:60]}...")
            
            # æ”¶é›†è¯¥ query çš„æ‰€æœ‰æ’å
            product_ranks = defaultdict(list)
            for result in self.session.results:
                if result.query_id == query_id and result.rankings:
                    for product, rank in result.rankings.items():
                        product_ranks[product].append(rank)
            
            if not product_ranks:
                print("  (æ— æœ‰æ•ˆæ’åæ•°æ®)")
                continue
            
            # è®¡ç®—å¹³å‡æ’åå¹¶æ’åº
            avg_ranks = []
            for product, ranks in product_ranks.items():
                avg = sum(ranks) / len(ranks)
                std = (sum((r - avg) ** 2 for r in ranks) / len(ranks)) ** 0.5
                avg_ranks.append((product, avg, std, ranks))
            
            avg_ranks.sort(key=lambda x: x[1])
            
            print(f"\n{'å•†å“åç§°':<55} {'å¹³å‡æ’å':>8} {'æ ‡å‡†å·®':>8} {'å„æ¬¡æ’å'}")
            print("-" * 95)
            for product, avg, std, ranks in avg_ranks:
                short_name = product[:50] + "..." if len(product) > 50 else product
                ranks_str = ",".join(str(r) for r in ranks)
                print(f"{short_name:<55} {avg:>8.2f} {std:>8.2f} {ranks_str}")
        
        print("\n" + "="*80)


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='VLM å•†å“æ’åå®éªŒ')
    parser.add_argument('--api-key', required=True, help='VLM API Key')
    parser.add_argument('--llm', choices=['openai', 'qwen'], default='qwen')
    parser.add_argument('--data-path', default='datasets_unified/ski_jacket.json', help='å•†å“æ•°æ® JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--runs', type=int, default=5, help='æ¯ä¸ª query è¿è¡Œæ¬¡æ•°')
    parser.add_argument('--log-dir', default='experiment_logs/ranking_experiment')
    
    args = parser.parse_args()
    
    # 4 ä¸ªæµ‹è¯• query
    queries = {
        "Q1_Backcountry_Pro": "I need a high-performance shell jacket for backcountry splitboarding. Priorities are breathability and weight over insulation. Must be 3-layer GORE-TEX (or equivalent), have pit zips, and a helmet-compatible hood.",
        
        "Q2_Budget_Beginner": "I'm a first-time skier going to a resort in March. Find me a highly-rated, insulated ski jacket under $200. I need something waterproof enough for resort grooming but don't need pro-level specs. Best value pick.",
        
        "Q3_Fashion_Luxury": "Find me a slim-fit, luxury-style women's ski suit that balances aesthetics with warmth. I prefer a monochrome or metallic look. Style and appearance are more important than technical specs.",
        
        "Q4_Extreme_Cold": "I'm looking for the warmest possible down-filled ski parka for resort skiing in extremely cold conditions (-15Â°C/5Â°F). It must be fully waterproof, not just water-resistant. Warmth is the top priority."
    }
    
    experiment = VLMRankingExperiment(
        llm_api_key=args.api_key,
        llm_backend=args.llm,
        data_path=args.data_path,
        log_dir=args.log_dir
    )
    
    experiment.run_experiment(queries, runs_per_query=args.runs)


if __name__ == "__main__":
    main()
